# ProveIT Edge Stack - PostgreSQL/TimescaleDB Configuration
# Optimized for unified architecture with 32GB RAM allocation
# Target: 1000+ tags @ 1Hz, billions of rows

# ============================================================
# MEMORY CONFIGURATION
# ============================================================

# Shared memory for all database operations
shared_buffers = 8GB                  # 25% of container RAM (32GB)
effective_cache_size = 24GB           # 75% of container RAM
maintenance_work_mem = 2GB            # For VACUUM, CREATE INDEX, etc.
work_mem = 256MB                      # Per operation memory
temp_buffers = 64MB                   # For temporary tables

# Huge pages for better memory performance (requires host config)
huge_pages = try                      # Use if available

# ============================================================
# CONNECTION MANAGEMENT
# ============================================================

listen_addresses = '*'
port = 5432
max_connections = 200                 # Sufficient for all services
superuser_reserved_connections = 5    # Reserved for admin

# Connection pools expected:
# - Ignition Gateway: 50 connections
# - Historian Writer: 50 connections
# - Flow Software: 20 connections
# - JupyterHub: 10 connections
# - Monitoring: 10 connections
# - Admin/Maintenance: 10 connections

# ============================================================
# WRITE PERFORMANCE (Critical for 1Hz data)
# ============================================================

# WAL Configuration
wal_level = replica                   # For replication/PITR
wal_buffers = 64MB                    # WAL memory buffer
wal_writer_delay = 200ms             # WAL writer frequency
wal_compression = on                  # Compress WAL files
max_wal_size = 16GB                   # Maximum WAL size
min_wal_size = 2GB                    # Minimum WAL retention
checkpoint_timeout = 15min            # Checkpoint frequency
checkpoint_completion_target = 0.9    # Spread checkpoint I/O
checkpoint_warning = 10min            # Warn if checkpoints are too frequent

# Commit behavior (optimize for high insert rate)
synchronous_commit = off              # Async commits for performance
commit_delay = 100                    # microseconds
commit_siblings = 5                   # Wait for other commits

# ============================================================
# PARALLEL PROCESSING
# ============================================================

max_worker_processes = 16             # Total background workers
max_parallel_workers_per_gather = 4   # Per-query parallelism
max_parallel_workers = 16             # Total parallel workers
max_parallel_maintenance_workers = 4  # For maintenance tasks
parallel_setup_cost = 100             # Lower to encourage parallelism
parallel_tuple_cost = 0.01            # Lower to encourage parallelism
min_parallel_table_scan_size = 8MB    # Enable parallel for smaller tables
min_parallel_index_scan_size = 512kB  # Enable parallel for index scans

# ============================================================
# TIMESCALEDB SPECIFIC
# ============================================================

shared_preload_libraries = 'timescaledb,pg_stat_statements'

# TimescaleDB workers
timescaledb.max_background_workers = 16
timescaledb.max_parallel_chunks_per_gather = 8

# Telemetry (disable for production)
timescaledb.telemetry_level = off

# ============================================================
# QUERY PLANNER
# ============================================================

# Cost parameters (SSD-optimized)
random_page_cost = 1.1                # SSD storage
seq_page_cost = 1.0                   # Sequential reads
cpu_tuple_cost = 0.01
cpu_index_tuple_cost = 0.005
cpu_operator_cost = 0.0025
effective_io_concurrency = 200        # SSD can handle many concurrent I/Os

# Planner options
enable_partitionwise_aggregate = on   # Better hypertable performance
enable_partitionwise_join = on        # Better hypertable joins
jit = on                              # JIT compilation
jit_above_cost = 100000               # Enable JIT for expensive queries
default_statistics_target = 100       # Better statistics

# ============================================================
# STATISTICS AND MONITORING
# ============================================================

# Query statistics
track_activities = on
track_counts = on
track_io_timing = on
track_functions = all
track_activity_query_size = 4096

# Statement statistics
pg_stat_statements.max = 10000
pg_stat_statements.track = all
pg_stat_statements.track_utility = on
pg_stat_statements.save = on

# ============================================================
# LOGGING
# ============================================================

logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0640
log_rotation_age = 1d
log_rotation_size = 100MB
log_truncate_on_rotation = off

# What to log
log_min_duration_statement = 1000     # Log queries slower than 1s
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_error_verbosity = default
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_lock_waits = on
log_temp_files = 0                    # Log all temp file usage
log_autovacuum_min_duration = 0       # Log all autovacuum
deadlock_timeout = 1s

# ============================================================
# AUTOVACUUM CONFIGURATION
# ============================================================

autovacuum = on
autovacuum_max_workers = 6            # Parallel vacuum workers
autovacuum_naptime = 10s              # Check frequency
autovacuum_vacuum_threshold = 50      # Min rows before vacuum
autovacuum_vacuum_insert_threshold = 1000  # For insert-only tables
autovacuum_analyze_threshold = 50     # Min rows before analyze
autovacuum_vacuum_scale_factor = 0.01 # 1% of table
autovacuum_analyze_scale_factor = 0.05 # 5% of table
autovacuum_freeze_max_age = 200000000
autovacuum_multixact_freeze_max_age = 400000000
autovacuum_vacuum_cost_delay = 2ms
autovacuum_vacuum_cost_limit = 1000   # Higher for faster vacuum

# ============================================================
# REPLICATION AND BACKUP
# ============================================================

# Archive configuration (for PITR)
archive_mode = on
archive_command = 'test ! -f /backup/wal/%f && cp %p /backup/wal/%f'
archive_timeout = 300                 # Force archive every 5 minutes

# Replication slots (if needed)
max_replication_slots = 4
max_wal_senders = 4
wal_keep_size = 4GB

# ============================================================
# RESOURCE LIMITS
# ============================================================

# Statement timeout (prevent runaway queries)
statement_timeout = 300000             # 5 minutes
lock_timeout = 60000                   # 1 minute
idle_in_transaction_session_timeout = 600000  # 10 minutes

# Temp file limits
temp_file_limit = 10GB                # Per-session temp file limit

# Lock management
max_locks_per_transaction = 128       # Increased for partitioned tables
max_pred_locks_per_transaction = 128

# ============================================================
# LOCALE AND FORMATTING
# ============================================================

datestyle = 'iso, mdy'
intervalstyle = 'postgres'
timezone = 'UTC'                      # Use UTC for consistency
lc_messages = 'en_US.utf8'
lc_monetary = 'en_US.utf8'
lc_numeric = 'en_US.utf8'
lc_time = 'en_US.utf8'
default_text_search_config = 'pg_catalog.english'

# ============================================================
# SECURITY
# ============================================================

# SSL (configure based on environment)
ssl = off                              # Enable in production
#ssl_cert_file = 'server.crt'
#ssl_key_file = 'server.key'
#ssl_ca_file = 'root.crt'

# Authentication timeout
authentication_timeout = 60s

# Password encryption
password_encryption = scram-sha-256